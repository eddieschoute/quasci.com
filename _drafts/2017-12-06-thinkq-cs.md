---
layout:     post
title:      ThinkQ Talks CS
date:       2017-12-06 16:38:05
summary:    ThinkQ conference experience
categories: conference algorithms advantage
---

The IBM ThinkQ conference was held recently in New York, with a focus on near-term quantum computing applications.
It seems that businesses that businesses have succesfully been developing larger quantum computers
---we're at around 50 qubits now!--- but are now looking for the "killer app" of small quantum computers.
There were some variations on the "what to do with you quantum computer" theme
and I will talk about some of the applications that were discussed.

All talks and recordings of them are available at the [online schedule](https://www.research.ibm.com/ibm-q/thinkq/agenda.html).

## Quantum Advantage
A _quantum advantage_ refers to some applications where a quantum computer performs some computation
that a classical computer currently cannot perform.
Previously known as _quantum supremacy_, it has now been renamed after an internal discussion
within the community about it's political correctness.
See e.g. one of the most heated [discussions](https://scirate.com/arxiv/1705.06768) I've seen on Scirate,
which also touches on the Latin origin of the term _ancilla_ ("housemaid", colloquially: helper qubit).
While almost certainly an internet troll, _ancilla the supremacist_ has become somewhat of a joke in my environment,
so I guess it has served its purpose.


## Applications
On the first day we had a high-level talk by Aram Harrow discussing some of the issues that
we face when finding applications that should exceed classical computers.
Usually computers are used for processing some amount of data, and reading all data will take at least $\Omega(n)$.
Therefore, if you do not have your data stored in some quantum format,
some obvious algorithms, such as Grover search, will actually be bound by this data read-out.
For example, if we wish to find a 1 in a pile of data, it takes $O(\sqrt n)$ after
reading out all bits in $O(n)$, resulting in just an $O(n)$ algorithm.
Obviously, in this use-case we would rather distribute the process over a classical data since that would be much faster.
